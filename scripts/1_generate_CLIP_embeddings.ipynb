{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook generates CLIP embeddings for News Nav photos on disk\n",
    "\n",
    "To convert to Python file:\n",
    "`jupyter nbconvert --to script generate_CLIP_embeddings.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR CLIP EMBEDDINGS\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import display\n",
    "import PIL.Image\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that splits a list into n chunks for multiprocessing\n",
    "def chunk(file_list, n_chunks):\n",
    "    \n",
    "    # make chunks of files to be distributed across processes\n",
    "    chunks = []\n",
    "    chunk_size = math.ceil(float(len(file_list))/n_chunks)\n",
    "    for i in range(0, n_chunks-1):\n",
    "        chunks.append(file_list[i*chunk_size:(i+1)*chunk_size])\n",
    "    chunks.append(file_list[(n_chunks-1)*chunk_size:])\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CLIP model (https://huggingface.co/sentence-transformers/clip-ViT-B-32)\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "print(\"Loaded model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function generates CLIP embeddings\n",
    "def generate_embeddings(year, file_list):\n",
    "\n",
    "    # iterate through PDFs\n",
    "    for i in range(0, len(file_list)):\n",
    "    \n",
    "        local_fp = file_list[i]\n",
    "                \n",
    "        filepath = local_fp.split('/')[-1]\n",
    "        \n",
    "        npy_filepath =  \"embeddings/\" + str(year) + \"_photos/\" + filepath.replace(\".jpg\", \".npy\")\n",
    "        \n",
    "#         # shows image\n",
    "#         display(IPImage(filename=local_fp))\n",
    "        \n",
    "        image = PIL.Image.open(local_fp, mode='r')\n",
    "        embedding = model.encode(image)\n",
    "                \n",
    "        np.save(npy_filepath, np.array(embedding))\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# need main for setting multiprocessing start method to spawn\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #     files = glob.glob('./../datasets/**/*')\n",
    "    \n",
    "    for year in range(1913, 1923):\n",
    "        print(\"PROCESSING YEAR: \" + str(year))\n",
    "        \n",
    "        files = glob.glob('./../datasets/' + str(year) + \"_photos/*\")\n",
    "        \n",
    "        print(\"DONE GLOBBING\")\n",
    "    \n",
    "        generate_embeddings(year, files)\n",
    "    \n",
    "        print(\"DONE EMBEDDINGS\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
